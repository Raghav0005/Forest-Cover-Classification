{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dl8MPr79sq3f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable warnings\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Turn off GPU usage for tf\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'"
      ],
      "metadata": {
        "id": "XwaGc6IW5-kU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_data(raw_df):\n",
        "  # preparing the data and obtaining necessary information\n",
        "  raw_data = raw_df.values\n",
        "  X = raw_data[:, :-1]\n",
        "  y = raw_data[:, -1]\n",
        "\n",
        "  print(X.shape, y.shape)\n",
        "\n",
        "  # performing the train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)\n",
        "\n",
        "  # standardizing the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_normalized = scaler.fit_transform(X_train)\n",
        "  X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "  return X_train_normalized, X_test_normalized, y_train, y_test"
      ],
      "metadata": {
        "id": "I_tigjsBydZP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_features):\n",
        "  # creating the Neural Network\n",
        "  classifier = keras.Sequential()\n",
        "  classifier.add(layers.Dense(64, input_dim=(num_features), activation=\"relu\"))\n",
        "  classifier.add(layers.Dense(32, activation=\"relu\"))\n",
        "  classifier.add(layers.Dense(8, activation=\"softmax\"))\n",
        "\n",
        "  classifier.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return classifier"
      ],
      "metadata": {
        "id": "2SG1_8_J7xld"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  raw_df = pd.read_csv(\"./cover_data.csv\")\n",
        "  columns = raw_df.columns.tolist()\n",
        "\n",
        "  features = columns[:-1]\n",
        "  label = columns[-1]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = prep_data(raw_df)\n",
        "\n",
        "  num_features = len(features)\n",
        "  model = build_model(num_features)\n",
        "\n",
        "  print(\"Summary Report of Model\")\n",
        "  model.summary()\n",
        "\n",
        "  num_epochs = 100\n",
        "  batch_size = 1024\n",
        "\n",
        "  earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=3)\n",
        "  history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[earlystop_callback],\n",
        "                        validation_split=0.1,\n",
        "                        verbose=1)\n",
        "\n",
        "  score = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(f'Test loss: {score[0]}')\n",
        "  print(f'Test accuracy: {score[1]}')\n",
        "\n",
        "  y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "  class_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
        "                   'Ponderosa Pine', 'Cottonwood/Willow',\n",
        "                   'Aspen', 'Douglas-fir', 'Krummholz']\n",
        "  print(classification_report(y_test, y_pred, target_names=class_names))\n"
      ],
      "metadata": {
        "id": "SOs-7P2QAEex"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3gvfO7Ermq",
        "outputId": "e9ee82ae-e2b1-4ec0-df87-a1cdb4134f74"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012, 54) (581012,)\n",
            "Summary Report of Model\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                3520      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 8)                 264       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5864 (22.91 KB)\n",
            "Trainable params: 5864 (22.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "409/409 [==============================] - 5s 6ms/step - loss: 0.7870 - accuracy: 0.6803 - val_loss: 0.6127 - val_accuracy: 0.7397\n",
            "Epoch 2/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.5827 - accuracy: 0.7515 - val_loss: 0.5624 - val_accuracy: 0.7573\n",
            "Epoch 3/100\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.5413 - accuracy: 0.7671 - val_loss: 0.5286 - val_accuracy: 0.7733\n",
            "Epoch 4/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.5151 - accuracy: 0.7786 - val_loss: 0.5073 - val_accuracy: 0.7827\n",
            "Epoch 5/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.4958 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7927\n",
            "Epoch 6/100\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.4802 - accuracy: 0.7966 - val_loss: 0.4794 - val_accuracy: 0.7965\n",
            "Epoch 7/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4675 - accuracy: 0.8032 - val_loss: 0.4637 - val_accuracy: 0.8056\n",
            "Epoch 8/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4566 - accuracy: 0.8087 - val_loss: 0.4542 - val_accuracy: 0.8084\n",
            "Epoch 9/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4475 - accuracy: 0.8125 - val_loss: 0.4457 - val_accuracy: 0.8121\n",
            "Epoch 10/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4402 - accuracy: 0.8160 - val_loss: 0.4429 - val_accuracy: 0.8127\n",
            "Epoch 11/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.4328 - accuracy: 0.8194 - val_loss: 0.4344 - val_accuracy: 0.8177\n",
            "Epoch 12/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.4261 - accuracy: 0.8219 - val_loss: 0.4261 - val_accuracy: 0.8230\n",
            "Epoch 13/100\n",
            "409/409 [==============================] - 3s 6ms/step - loss: 0.4207 - accuracy: 0.8246 - val_loss: 0.4203 - val_accuracy: 0.8253\n",
            "Epoch 14/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4153 - accuracy: 0.8274 - val_loss: 0.4148 - val_accuracy: 0.8270\n",
            "Epoch 15/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4113 - accuracy: 0.8292 - val_loss: 0.4111 - val_accuracy: 0.8285\n",
            "Epoch 16/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4070 - accuracy: 0.8312 - val_loss: 0.4068 - val_accuracy: 0.8316\n",
            "Epoch 17/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.4030 - accuracy: 0.8330 - val_loss: 0.4019 - val_accuracy: 0.8336\n",
            "Epoch 18/100\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.3997 - accuracy: 0.8349 - val_loss: 0.4017 - val_accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3962 - accuracy: 0.8363 - val_loss: 0.3970 - val_accuracy: 0.8368\n",
            "Epoch 20/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3937 - accuracy: 0.8374 - val_loss: 0.3992 - val_accuracy: 0.8348\n",
            "Epoch 21/100\n",
            "409/409 [==============================] - 3s 8ms/step - loss: 0.3908 - accuracy: 0.8393 - val_loss: 0.3942 - val_accuracy: 0.8365\n",
            "Epoch 22/100\n",
            "409/409 [==============================] - 3s 8ms/step - loss: 0.3879 - accuracy: 0.8402 - val_loss: 0.3893 - val_accuracy: 0.8379\n",
            "Epoch 23/100\n",
            "409/409 [==============================] - 3s 6ms/step - loss: 0.3854 - accuracy: 0.8414 - val_loss: 0.3859 - val_accuracy: 0.8416\n",
            "Epoch 24/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3823 - accuracy: 0.8430 - val_loss: 0.3835 - val_accuracy: 0.8395\n",
            "Epoch 25/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3801 - accuracy: 0.8439 - val_loss: 0.3833 - val_accuracy: 0.8427\n",
            "Epoch 26/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3783 - accuracy: 0.8447 - val_loss: 0.3793 - val_accuracy: 0.8423\n",
            "Epoch 27/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3763 - accuracy: 0.8453 - val_loss: 0.3771 - val_accuracy: 0.8445\n",
            "Epoch 28/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.3746 - accuracy: 0.8461 - val_loss: 0.3740 - val_accuracy: 0.8446\n",
            "Epoch 29/100\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.3722 - accuracy: 0.8473 - val_loss: 0.3725 - val_accuracy: 0.8451\n",
            "Epoch 30/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3699 - accuracy: 0.8479 - val_loss: 0.3744 - val_accuracy: 0.8461\n",
            "Epoch 31/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3686 - accuracy: 0.8490 - val_loss: 0.3735 - val_accuracy: 0.8451\n",
            "Epoch 32/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3667 - accuracy: 0.8496 - val_loss: 0.3677 - val_accuracy: 0.8479\n",
            "Epoch 33/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3644 - accuracy: 0.8504 - val_loss: 0.3668 - val_accuracy: 0.8479\n",
            "Epoch 34/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.3631 - accuracy: 0.8512 - val_loss: 0.3648 - val_accuracy: 0.8488\n",
            "Epoch 35/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.3618 - accuracy: 0.8515 - val_loss: 0.3655 - val_accuracy: 0.8494\n",
            "Epoch 36/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3606 - accuracy: 0.8520 - val_loss: 0.3650 - val_accuracy: 0.8492\n",
            "Epoch 37/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3591 - accuracy: 0.8527 - val_loss: 0.3637 - val_accuracy: 0.8498\n",
            "Epoch 38/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3578 - accuracy: 0.8536 - val_loss: 0.3580 - val_accuracy: 0.8517\n",
            "Epoch 39/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3564 - accuracy: 0.8539 - val_loss: 0.3605 - val_accuracy: 0.8514\n",
            "Epoch 40/100\n",
            "409/409 [==============================] - 3s 6ms/step - loss: 0.3552 - accuracy: 0.8547 - val_loss: 0.3564 - val_accuracy: 0.8517\n",
            "Epoch 41/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.3547 - accuracy: 0.8547 - val_loss: 0.3551 - val_accuracy: 0.8541\n",
            "Epoch 42/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3532 - accuracy: 0.8556 - val_loss: 0.3574 - val_accuracy: 0.8536\n",
            "Epoch 43/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.8557 - val_loss: 0.3577 - val_accuracy: 0.8510\n",
            "Epoch 44/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.8562 - val_loss: 0.3518 - val_accuracy: 0.8549\n",
            "Epoch 45/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3503 - accuracy: 0.8567 - val_loss: 0.3509 - val_accuracy: 0.8554\n",
            "Epoch 46/100\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.3489 - accuracy: 0.8572 - val_loss: 0.3525 - val_accuracy: 0.8540\n",
            "Epoch 47/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.3483 - accuracy: 0.8575 - val_loss: 0.3510 - val_accuracy: 0.8541\n",
            "Epoch 48/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3473 - accuracy: 0.8578 - val_loss: 0.3499 - val_accuracy: 0.8559\n",
            "Epoch 49/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3462 - accuracy: 0.8583 - val_loss: 0.3513 - val_accuracy: 0.8559\n",
            "Epoch 50/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3446 - accuracy: 0.8589 - val_loss: 0.3450 - val_accuracy: 0.8590\n",
            "Epoch 51/100\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.3442 - accuracy: 0.8593 - val_loss: 0.3459 - val_accuracy: 0.8566\n",
            "Epoch 52/100\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.3436 - accuracy: 0.8595 - val_loss: 0.3501 - val_accuracy: 0.8531\n",
            "Epoch 53/100\n",
            "409/409 [==============================] - 3s 7ms/step - loss: 0.3424 - accuracy: 0.8596 - val_loss: 0.3443 - val_accuracy: 0.8584\n",
            "Test loss: 0.34844279289245605\n",
            "Test accuracy: 0.8572842478752136\n",
            "3632/3632 [==============================] - 6s 2ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "       Spruce/Fir       0.86      0.84      0.85     42368\n",
            "   Lodgepole Pine       0.87      0.89      0.88     56661\n",
            "   Ponderosa Pine       0.86      0.81      0.83      7151\n",
            "Cottonwood/Willow       0.77      0.76      0.76       549\n",
            "            Aspen       0.73      0.52      0.61      1899\n",
            "      Douglas-fir       0.66      0.73      0.69      3473\n",
            "        Krummholz       0.91      0.83      0.87      4102\n",
            "\n",
            "         accuracy                           0.86    116203\n",
            "        macro avg       0.81      0.77      0.79    116203\n",
            "     weighted avg       0.86      0.86      0.86    116203\n",
            "\n"
          ]
        }
      ]
    }
  ]
}